{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a4fadb46-bdfe-4b25-bcca-2b8789154585",
      "metadata": {
        "tags": [],
        "id": "a4fadb46-bdfe-4b25-bcca-2b8789154585"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vEd_TMzTKSr",
        "outputId": "34f7f80c-7527-46b6-89b0-17e2e2999b4d"
      },
      "id": "5vEd_TMzTKSr",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7c6adbad-9487-4913-b4c7-3b53dd203357",
      "metadata": {
        "tags": [],
        "id": "7c6adbad-9487-4913-b4c7-3b53dd203357"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "951792a7-0728-4933-87b4-c7e90c3aa932",
      "metadata": {
        "tags": [],
        "id": "951792a7-0728-4933-87b4-c7e90c3aa932"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "01a56e3c-fdf5-4f49-ad8f-3e041ad7b491",
      "metadata": {
        "tags": [],
        "id": "01a56e3c-fdf5-4f49-ad8f-3e041ad7b491"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ada652ef-2662-41bf-90d2-26851068fa3b",
      "metadata": {
        "tags": [],
        "id": "ada652ef-2662-41bf-90d2-26851068fa3b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "59ed9859-9654-48d5-afab-63ad99edea78",
      "metadata": {
        "tags": [],
        "id": "59ed9859-9654-48d5-afab-63ad99edea78"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b6f3566f-09f8-45a6-95ae-ba6177a4db88",
      "metadata": {
        "tags": [],
        "id": "b6f3566f-09f8-45a6-95ae-ba6177a4db88"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5e34822b-bf9d-46e2-aeb1-1f65d56e8d79",
      "metadata": {
        "tags": [],
        "id": "5e34822b-bf9d-46e2-aeb1-1f65d56e8d79"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0650fd62-c9e2-41b9-9e72-69464d9b4cbb",
      "metadata": {
        "tags": [],
        "id": "0650fd62-c9e2-41b9-9e72-69464d9b4cbb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b9c197af-5eb4-4d7f-ae67-622dff75fbe4",
      "metadata": {
        "tags": [],
        "id": "b9c197af-5eb4-4d7f-ae67-622dff75fbe4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5266e4bb-49c8-4a75-8647-2db28c8021cf",
      "metadata": {
        "tags": [],
        "id": "5266e4bb-49c8-4a75-8647-2db28c8021cf"
      },
      "outputs": [],
      "source": [
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "30aeb6e2-e634-49a9-9655-39f10942f03e",
      "metadata": {
        "tags": [],
        "id": "30aeb6e2-e634-49a9-9655-39f10942f03e"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "25acc687-614a-45ac-9e20-4b235949d699",
      "metadata": {
        "tags": [],
        "id": "25acc687-614a-45ac-9e20-4b235949d699"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4057367-e5c3-4a16-a688-951dbfdf7b9b",
      "metadata": {
        "id": "b4057367-e5c3-4a16-a688-951dbfdf7b9b"
      },
      "source": [
        "## Basic set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b92b4ef4-092b-4407-918b-fffb61106ab3",
      "metadata": {
        "tags": [],
        "id": "b92b4ef4-092b-4407-918b-fffb61106ab3"
      },
      "outputs": [],
      "source": [
        "labels = ['glioma_tumor', 'no_tumor','meningioma_tumor','pituitary_tumor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "13a86f2d-dad8-4306-9cdf-eb0bd3ead2d9",
      "metadata": {
        "tags": [],
        "id": "13a86f2d-dad8-4306-9cdf-eb0bd3ead2d9"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "os.getcwd()\n",
        "os.chdir('/content/drive/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0afdc244-2ca2-4d3f-a922-3af42eb0972f",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0afdc244-2ca2-4d3f-a922-3af42eb0972f",
        "outputId": "1d655ffe-d82e-44c3-da0f-16d98b80e931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 826/826 [00:05<00:00, 150.68it/s]\n",
            "100%|██████████| 395/395 [00:02<00:00, 193.40it/s]\n",
            "100%|██████████| 822/822 [00:05<00:00, 154.72it/s]\n",
            "100%|██████████| 827/827 [00:05<00:00, 148.83it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 184.85it/s]\n",
            "100%|██████████| 105/105 [00:00<00:00, 263.76it/s]\n",
            "100%|██████████| 115/115 [00:00<00:00, 227.13it/s]\n",
            "100%|██████████| 74/74 [00:00<00:00, 114.18it/s]\n"
          ]
        }
      ],
      "source": [
        "#scaling our images to 150px by 150px to make training easier/convenient\n",
        "scaleDown = 150\n",
        "#these 2 for loops are horrendous i know, i can't be bothered to make them more elegant, sorry\n",
        "for i in labels: \n",
        "    folderPath = os.path.join('Training', i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath, j))\n",
        "        img = cv2.resize(img, (scaleDown, scaleDown))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "        \n",
        "for i in labels:\n",
        "    folderPath = os.path.join('Testing', i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath, j))\n",
        "        img = cv2.resize(img, (scaleDown, scaleDown))\n",
        "        X_train.append(img)\n",
        "        y_train.append(i)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1efa3b27-01f3-4bc1-ac26-00d2dd282c34",
      "metadata": {
        "tags": [],
        "id": "1efa3b27-01f3-4bc1-ac26-00d2dd282c34"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = shuffle(X_train, y_train, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0c18e416-d8a7-432f-9332-82426de5a6a0",
      "metadata": {
        "tags": [],
        "id": "0c18e416-d8a7-432f-9332-82426de5a6a0",
        "outputId": "1f96bbfc-6885-444f-83dd-23aa390d0579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3264, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "50f0134e-fb7a-4ac6-99e7-0c084e5a5a05",
      "metadata": {
        "tags": [],
        "id": "50f0134e-fb7a-4ac6-99e7-0c084e5a5a05"
      },
      "outputs": [],
      "source": [
        "#The (3002, 150, 150, 3) is the final shape of our training data (the 3002 images that have been scaled to\n",
        "# 150x150px with 3 channels and converted to an np array)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b95b3830-0755-4ac8-8a89-2f8329ca0d78",
      "metadata": {
        "tags": [],
        "id": "b95b3830-0755-4ac8-8a89-2f8329ca0d78"
      },
      "source": [
        "### Splitting the Data into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "481e4383-3f14-4361-9c95-b7b17d36816e",
      "metadata": {
        "tags": [],
        "id": "481e4383-3f14-4361-9c95-b7b17d36816e"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.08, random_state=101)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "136f1990-44ff-4b98-9f54-ebdfa01dfd17",
      "metadata": {
        "id": "136f1990-44ff-4b98-9f54-ebdfa01dfd17"
      },
      "source": [
        "### Converting the text based values of the y_train array into numerical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7aa1af59-1b59-4782-9bef-74569b55193c",
      "metadata": {
        "tags": [],
        "id": "7aa1af59-1b59-4782-9bef-74569b55193c"
      },
      "outputs": [],
      "source": [
        "y_train_final = []\n",
        "for i in y_train:\n",
        "    y_train_final.append(labels.index(i))\n",
        "y_train = y_train_final\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "\n",
        "\n",
        "y_test_final = []\n",
        "for i in y_test:\n",
        "    y_test_final.append(labels.index(i))\n",
        "y_test = y_test_final\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3c516677-2c76-4a40-910d-bd90f7820a3f",
      "metadata": {
        "tags": [],
        "id": "3c516677-2c76-4a40-910d-bd90f7820a3f"
      },
      "outputs": [],
      "source": [
        "effnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(scaleDown, scaleDown,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d1100e0c-0f8a-4aae-8a9a-49d3de8399e6",
      "metadata": {
        "tags": [],
        "id": "d1100e0c-0f8a-4aae-8a9a-49d3de8399e6"
      },
      "outputs": [],
      "source": [
        "model = effnet.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3b4edbd2-6de7-485d-98fb-34b2e6213ffa",
      "metadata": {
        "tags": [],
        "id": "3b4edbd2-6de7-485d-98fb-34b2e6213ffa"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
        "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
        "model = tf.keras.layers.Dense(4, activation='softmax')(model)\n",
        "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b9a87750-f302-471d-918d-ee46c5470401",
      "metadata": {
        "tags": [],
        "id": "b9a87750-f302-471d-918d-ee46c5470401"
      },
      "outputs": [],
      "source": [
        "# model.summary() to get a useful summary about our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bd6d1cf2-ffe0-4af3-bff6-82bfde1aeb3d",
      "metadata": {
        "tags": [],
        "id": "bd6d1cf2-ffe0-4af3-bff6-82bfde1aeb3d"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "44d6718f-41cf-4cf6-b70c-bb2dc4083c4b",
      "metadata": {
        "tags": [],
        "id": "44d6718f-41cf-4cf6-b70c-bb2dc4083c4b"
      },
      "outputs": [],
      "source": [
        "#callbacks\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='training1.chkpt',save_weights_only=True,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor=0.3, patience=2, min_delta=0.001, mode='auto', verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e65f8566-2f05-4f44-9711-5819a8629393",
      "metadata": {
        "id": "e65f8566-2f05-4f44-9711-5819a8629393",
        "outputId": "c2f090c9-0b8b-46de-8ccb-a7a948ea62ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9464\n",
            "Epoch 1: saving model to training1.chkpt\n",
            "70/70 [==============================] - 264s 4s/step - loss: 0.1598 - accuracy: 0.9464 - val_loss: 0.4087 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 2/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9660\n",
            "Epoch 2: saving model to training1.chkpt\n",
            "70/70 [==============================] - 257s 4s/step - loss: 0.1027 - accuracy: 0.9660 - val_loss: 0.3547 - val_accuracy: 0.9087 - lr: 0.0010\n",
            "Epoch 3/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9804\n",
            "Epoch 3: saving model to training1.chkpt\n",
            "70/70 [==============================] - 257s 4s/step - loss: 0.0680 - accuracy: 0.9804 - val_loss: 0.6780 - val_accuracy: 0.7925 - lr: 0.0010\n",
            "Epoch 4/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.9786\n",
            "Epoch 4: saving model to training1.chkpt\n",
            "70/70 [==============================] - 260s 4s/step - loss: 0.0721 - accuracy: 0.9786 - val_loss: 0.2662 - val_accuracy: 0.9253 - lr: 0.0010\n",
            "Epoch 5/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9783\n",
            "Epoch 5: saving model to training1.chkpt\n",
            "70/70 [==============================] - 283s 4s/step - loss: 0.0614 - accuracy: 0.9783 - val_loss: 0.3571 - val_accuracy: 0.8963 - lr: 0.0010\n",
            "Epoch 6/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9685\n",
            "Epoch 6: saving model to training1.chkpt\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "70/70 [==============================] - 282s 4s/step - loss: 0.1012 - accuracy: 0.9685 - val_loss: 0.3324 - val_accuracy: 0.9129 - lr: 0.0010\n",
            "Epoch 7/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9888\n",
            "Epoch 7: saving model to training1.chkpt\n",
            "70/70 [==============================] - 258s 4s/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.1428 - val_accuracy: 0.9544 - lr: 3.0000e-04\n",
            "Epoch 8/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9931\n",
            "Epoch 8: saving model to training1.chkpt\n",
            "70/70 [==============================] - 256s 4s/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.1069 - val_accuracy: 0.9627 - lr: 3.0000e-04\n",
            "Epoch 9/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9975\n",
            "Epoch 9: saving model to training1.chkpt\n",
            "70/70 [==============================] - 257s 4s/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0872 - val_accuracy: 0.9585 - lr: 3.0000e-04\n",
            "Epoch 10/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
            "Epoch 10: saving model to training1.chkpt\n",
            "70/70 [==============================] - 261s 4s/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.1010 - val_accuracy: 0.9668 - lr: 3.0000e-04\n",
            "Epoch 11/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9989\n",
            "Epoch 11: saving model to training1.chkpt\n",
            "70/70 [==============================] - 256s 4s/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1001 - val_accuracy: 0.9627 - lr: 3.0000e-04\n",
            "Epoch 12/12\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
            "Epoch 12: saving model to training1.chkpt\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "70/70 [==============================] - 260s 4s/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1118 - val_accuracy: 0.9668 - lr: 3.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,y_train,validation_split=0.08, epochs=12, verbose=1, batch_size=40, callbacks=[tensorboard, cp_callback,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('saved_model/my_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "aPKvAsh5_Kj9",
        "outputId": "cfad2439-578c-4d86-bab9-839768e692a5"
      },
      "id": "aPKvAsh5_Kj9",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e7f63eb74120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model/my_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqLNXKiT-vth",
        "outputId": "9f6370ac-bc28-450d-85a3-06a9bf78ddde"
      },
      "id": "TqLNXKiT-vth",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 8s 669ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4c176dd6-ed7b-4f91-8c10-75cd01d21082",
      "metadata": {
        "tags": [],
        "id": "4c176dd6-ed7b-4f91-8c10-75cd01d21082"
      },
      "outputs": [],
      "source": [
        "pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6723ee23-4a3c-4b95-a1f3-8193629c5f13",
      "metadata": {
        "tags": [],
        "id": "6723ee23-4a3c-4b95-a1f3-8193629c5f13"
      },
      "outputs": [],
      "source": [
        "y_test_final = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f3fbee46-0fa7-40e8-a082-8397eeda269d",
      "metadata": {
        "tags": [],
        "id": "f3fbee46-0fa7-40e8-a082-8397eeda269d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78b94b9-1f2d-4854-e711-d1cc44e9a5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94        72\n",
            "           1       0.98      1.00      0.99        41\n",
            "           2       0.94      0.96      0.95        83\n",
            "           3       0.99      1.00      0.99        66\n",
            "\n",
            "    accuracy                           0.97       262\n",
            "   macro avg       0.97      0.97      0.97       262\n",
            "weighted avg       0.97      0.97      0.97       262\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_final,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d6ced2-d6c5-4b78-9033-9a7c279bdbc7",
      "metadata": {
        "id": "03d6ced2-d6c5-4b78-9033-9a7c279bdbc7"
      },
      "source": [
        "## Loading a new image and making a prediction using our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "8b21b2a0-23f1-4090-bcbd-ed42751bee8e",
      "metadata": {
        "tags": [],
        "id": "8b21b2a0-23f1-4090-bcbd-ed42751bee8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b4cc12-6b5d-4614-b3cc-514c058d3a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "The Model predicts : Pituitary Tumor\n"
          ]
        }
      ],
      "source": [
        "img = Image.open(r\"ImagesForPrediction/ls44dcxet1487oinyhhiqas13d5f.jpg\")\n",
        "opencvImage = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "img = cv2.resize(opencvImage, (150,150))\n",
        "img = img.reshape(1,150,150,3)\n",
        "prediction = model.predict(img)\n",
        "prediction = np.argmax(prediction,axis=1)[0]\n",
        "    \n",
        "    \n",
        "if prediction==0:\n",
        "    prediction='Glioma'\n",
        "elif prediction==1:\n",
        "    prediction='No Tumor'\n",
        "elif prediction==2:\n",
        "        prediction='Meningioma'\n",
        "elif prediction==3:\n",
        "    prediction='Pituitary Tumor'\n",
        "    \n",
        "print(f'The Model predicts : {prediction}')    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cf9a71-c26f-4eaf-9dd4-1689a5a2d326",
      "metadata": {
        "id": "64cf9a71-c26f-4eaf-9dd4-1689a5a2d326"
      },
      "outputs": [],
      "source": [
        "#@title Loading saved modules \n",
        "\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()\n",
        "\n",
        "# Check its accuracy\n",
        "loss, acc = new_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3f0118-83c7-4c5b-8548-ffcc60072f8c",
      "metadata": {
        "id": "1e3f0118-83c7-4c5b-8548-ffcc60072f8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e003201-8a2d-4b68-a1e1-5055ffd9924e",
      "metadata": {
        "id": "8e003201-8a2d-4b68-a1e1-5055ffd9924e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18376258-76f6-441d-b280-621dfe5d0828",
      "metadata": {
        "id": "18376258-76f6-441d-b280-621dfe5d0828"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}